{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tread safe hashtable stress test",
   "id": "1ab64e1a90836714"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T19:19:06.454932Z",
     "start_time": "2025-11-14T19:19:06.449288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import random\n",
    "import threading\n",
    "\n",
    "from project.task5.hash_table import HashTable\n",
    "from project.task6.parallel_hash_table import HashTable as BaselineHashTable\n",
    "\n",
    "TOTAL_OPS = 5_000_000\n",
    "READ_RATIO = 0.80\n",
    "NUM_THREADS = 8\n",
    "KEY_SPACE = 20000"
   ],
   "id": "b30ac16e1f881bf8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import sources directory\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-14T17:19:49.794739Z",
     "start_time": "2025-11-14T17:19:49.791283Z"
    }
   },
   "cell_type": "markdown",
   "source": "## Creating operations set",
   "id": "539587fa6a6741a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T19:27:36.379022Z",
     "start_time": "2025-11-14T19:27:36.375990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_operations(total_ops, read_ratio, key_space, seed=0):\n",
    "    rng = random.Random(seed)\n",
    "    ops = []\n",
    "    for _ in range(total_ops):\n",
    "        if rng.random() < read_ratio:\n",
    "            ops.append(('get', rng.randrange(0, key_space), None))\n",
    "        else:\n",
    "            # writes: either set or delete; make set more probable\n",
    "            if rng.random() < 0.9:\n",
    "                ops.append(('set', rng.randrange(0, key_space), rng.randrange(1, 1 << 30)))\n",
    "            else:\n",
    "                ops.append(('del', rng.randrange(0, key_space), None))\n",
    "    return ops"
   ],
   "id": "69a0134bca9bd7b2",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Operations execution rules",
   "id": "8c50bcdd19f81207"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T19:26:17.446668Z",
     "start_time": "2025-11-14T19:26:17.442506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_ops_on_table(table, ops, num_threads):\n",
    "    # split ops among threads\n",
    "    chunk = len(ops) // num_threads\n",
    "    threads = []\n",
    "    start_t = time.time()\n",
    "    def worker(subops):\n",
    "        for op, k, v in subops:\n",
    "            try:\n",
    "                if op == 'get':\n",
    "                    try:\n",
    "                        _ = table[k]\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                elif op == 'set':\n",
    "                    table[k] = v\n",
    "                elif op == 'del':\n",
    "                    try:\n",
    "                        del table[k]\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "            except IndexError:\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                print(\"Exception during op:\", e)\n",
    "\n",
    "\n",
    "    for i in range(num_threads):\n",
    "        s = i * chunk\n",
    "        e = len(ops) if i == num_threads - 1 else s + chunk\n",
    "        t = threading.Thread(target=worker, args=(ops[s:e],))\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    end_t = time.time()\n",
    "    return end_t - start_t"
   ],
   "id": "8ff27c6fe90581a3",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Treadsafe hashtable run",
   "id": "ce22187d49b2279"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T19:27:45.615608Z",
     "start_time": "2025-11-14T19:27:40.498369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ops = generate_operations(TOTAL_OPS, READ_RATIO, KEY_SPACE, seed=12345)\n",
    "print(\"Operations generated:\", len(ops))\n",
    "print(\"Running stress test on thread-safe hash table...\")\n",
    "ts_table = HashTable(initial_capacity=64)\n",
    "t_ts = run_ops_on_table(ts_table, ops, NUM_THREADS)\n",
    "print(f\"Thread-safe table: time {t_ts:.2f}s, final size {len(ts_table)}\")"
   ],
   "id": "8e8ddb488d7fe3fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operations generated: 5000000\n",
      "Running stress test on thread-safe hash table...\n",
      "Thread-safe table: time 2.18s, final size 17926\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Baseline hashtable run",
   "id": "76753b9343ae3f1d"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-14T19:27:57.855503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Работал дольше часа и не завершился\n",
    "ops2 = generate_operations(TOTAL_OPS, READ_RATIO, KEY_SPACE, seed=12345)\n",
    "base_table = BaselineHashTable(initial_capacity=64)\n",
    "t_base = run_ops_on_table(base_table, ops2, NUM_THREADS)\n",
    "print(f\"Baseline table: time {t_base:.2f}s, final size {len(base_table)}\")"
   ],
   "id": "336b3ac2e7dc2e63",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
